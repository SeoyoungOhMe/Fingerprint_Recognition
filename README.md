# ì§€ë¬¸ì¸ì‹ í”„ë¡œê·¸ë¨â˜ï¸
### ê¸°ê°„
2024.05~2024.06

### ê°œë°œ í™˜ê²½
- Jupyter Notebook
- Python3

### ì„¤ëª…
ìƒì²´ì¸ì¦ë³´ì•ˆ ê³¼ëª©ì—ì„œ ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸ëŠ” ì§€ë¬¸ ì¸ì‹ì„ ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ê³  ì„±ëŠ¥ì„ ë¶„ì„í•˜ëŠ” í”„ë¡œì íŠ¸ì˜€ìŠµë‹ˆë‹¤. 

ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ë©° ì´ë¯¸ì§€ ì „ì²˜ë¦¬, íŠ¹ì§• ì¶”ì¶œ, ë§¤ì¹­ì„ ê±°ì³¤ìŠµë‹ˆë‹¤.    
`ì´ë¯¸ì§€ ì „ì²˜ë¦¬` ë‹¨ê³„ì—ì„œëŠ” Gaussian blur, Erosion, Morphological Operations ë“± ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ë¥¼ ì‹œë„í•´ë³´ì•˜ìŠµë‹ˆë‹¤.    
`íŠ¹ì§• ì¶”ì¶œ` ë‹¨ê³„ì—ì„œëŠ” 3x3 ìœˆë„ìš°ë¥¼ ì‚¬ìš©í•´ Minutiaeì˜ ëì ê³¼ ë¶„ê¸°ì ì„ ê²€ì¶œí•˜ì˜€ìœ¼ë©°, ì‹¤í–‰ì‹œê°„ì„ ë¶„ì„í•´ ê°€ëŠ¥í•œ ê²½ìš° ì†ë„ë¥¼ ìµœì í™”í–ˆìŠµë‹ˆë‹¤.     
`ë§¤ì¹­` ë‹¨ê³„ì—ì„œëŠ” Testsetì˜ ìƒ˜í”Œê³¼ trainset ì§€ë¬¸ì„ ë¹„êµí•˜ì—¬ ë§¤ì¹­í–ˆìœ¼ë©°, ì¼ë¶€ í¸ì§‘ëœ ë°ì´í„°ì˜ ê²½ìš° í¬ì¦ˆê°€ ë™ì¼í•˜ë¯€ë¡œ ê±°ë¦¬ë§Œ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.     
ë§ˆì§€ë§‰ìœ¼ë¡œ Precision, Recall, FAR, FRR, ACC ë“±ì˜ `Metricì„ ê³„ì‚°`í•˜ê³  ì ì ˆí•œ thresholdë¥¼ ì„¤ì •í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.    

---
# ë³´ê³ ì„œğŸ“ƒ
ë¨¼ì € í…ŒìŠ¤íŠ¸ì…‹ì„ list_test2ë¡œ ë¶ˆëŸ¬ì˜¤ê³ , list_test2[0]ì™€ í•´ë‹¹ ì´ë¦„ê³¼ ì¼ì¹˜í•˜ëŠ” íŠ¸ë ˆì´ë‹ ì´ë¯¸ì§€ ê²½ë¡œì˜ ì´ë¯¸ì§€ë¥¼ ê°ê° img1, img2ë¡œ ì €ì¥í–ˆë‹¤. ëª¨ë“  í…ŒìŠ¤íŠ¸ì…‹ê³¼ íŠ¸ë ˆì´ë‹ì…‹ì„ ë¹„êµí•˜ê¸° ì „ì—, ì´ ë‘ ì´ë¯¸ì§€ë¡œ distanceê°€ ì–´ëŠ ì •ë„ ë‚˜ì˜¤ëŠ”ì§€ë¥¼ ë³´ê³ ì í–ˆë‹¤. 

## ì›ë³¸ ì´ë¯¸ì§€

img1, img2ë¥¼ ê°ê° ì¶œë ¥í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì˜¨ë‹¤.
![1](https://github.com/user-attachments/assets/b2b96595-ed7a-4f4f-9ca5-f686fe5e1283)

## ì´ë¯¸ì§€ ì „ì²˜ë¦¬

### Pose - Affine Transform

img1ì— ëŒ€í•´ affine matrix ë³€í™˜ ê³¼ì •ì„ ì¶œë ¥í•´ë³´ê³ , ë³€í™˜ ì „í›„ì˜ ì¢Œí‘œë¥¼ íŒŒë€ìƒ‰ê³¼ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ì°ì–´ë³´ì•˜ë‹¤.
![2](https://github.com/user-attachments/assets/090bb7f9-9bc3-44fc-8a60-b7f975505c06)
![3](https://github.com/user-attachments/assets/5aa8fbc4-d1e5-461c-a454-01f45b6f5871)

45ë„ íšŒì „ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì•˜ë‹¤.
![4](https://github.com/user-attachments/assets/904f212d-302d-4052-a7ab-ee74bcbab201)


### Filtering

í•„í„°ë§ì´ êµ‰ì¥íˆ ì–´ë ¤ì› ë‹¤. ì§ì ‘ 3x3 ì»¤ë„ì„ ìˆ˜ì •í•´ë³´ë©° ë‹¤ìŒì˜ í•„í„°ë§ì´ ê·¸ë‚˜ë§ˆ ê²°ê³¼ê°€ ê´œì°®ì•„ì„œ ì ìš©í–ˆë‹¤.

```python
ks = 3
kernel = np.array(( 
    [ 0, -1,  0],
    [-1,  5, -1],
    [ 0, -1,  0]
))
```

img1ì˜ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì•˜ë‹¤.
![5](https://github.com/user-attachments/assets/4845e467-9cb9-4367-8507-0be4465587eb)


ì—¬ì „íˆ ì£¼ë³€ì— ë…¸ì´ì¦ˆê°€ ë§ê³  ìœµì„ ì´ ë˜ë ·í•˜ì§€ ì•Šì€ ê²ƒ ê°™ì•˜ë‹¤. ê·¸ë˜ì„œ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ í†µí•´ ë…¸ì´ì¦ˆë¥¼ ê°ì†Œí•˜ê³ , CLAHEë¥¼ ì´ìš©í•´ ëª…ì•”ì„ ê· ì¼í™”í•œ í›„, Otsuâ€™s ì´ì§„í™”ë¥¼ í†µí•´ ë‹¤ì–‘í•œ í•„í„°ë§ì„ ì ìš©í–ˆë‹¤. ë§ˆì§€ë§‰ì—ëŠ” ëª…ì•” ë°˜ì „ì„ í–ˆë‹¤.

```python
def process_image(image):
    # Step 1: ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ì´ë¯¸ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì´ë©´ í•„ìš” ì—†ìŒ)
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Step 2: ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì ìš©í•˜ì—¬ ë…¸ì´ì¦ˆ ê°ì†Œ
    blurred = cv2.GaussianBlur(image, (5, 5), 0)
    
    # Step 3: CLAHEë¥¼ ì ìš©í•˜ì—¬ ëª…ì•” ê· ì¼í™”
    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    clahe_image = clahe.apply(blurred)
    
    # Step 4: Otsuì˜ ì´ì§„í™”ë¥¼ ì ìš©
    _, binary_image = cv2.threshold(clahe_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # Step 5: ê²€ì •ê³¼ í°ìƒ‰ ë°˜ì „
    inverted_image = cv2.bitwise_not(binary_image)

    # ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ì €ì¥
    images = {
        'Original Image': image,
        'Gaussian Blurred Image': blurred,
        'Clahe Image' : clahe_image,\
        'Otsu\'s Binarized Image': binary_image,
        'Inverted Image': inverted_image
    }

    return images
```

ì´ ê³¼ì •ì„ ì´ë¯¸ì§€ë¡œ ì¶œë ¥í•´ë³´ë‹ˆ ë‹¤ìŒì˜ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤.
![6](https://github.com/user-attachments/assets/c94004ba-c0f8-4126-8132-1dbc2e591710)


ì—¬ì „íˆ ë§ˆìŒì— ë“¤ì§€ ì•ŠëŠ” ë¶€ë¶„ì€ ìœµì„ ë“¤ì´ ì¤‘ê°„ì— ë¶ˆí•„ìš”í•˜ê²Œ ì—°ê²°ëœ ë¶€ë¶„ë“¤ê³¼ ì£¼ë³€ì˜ ë…¸ì´ì¦ˆì´ë‹¤. ìµœëŒ€í•œ ì„ ì„ ê¹”ë”í•˜ê²Œ ë§Œë“¤ì–´ ë³´ë ¤ê³  Morphology ì—°ì‚°(ì¹¨ì‹, Opening) ë“± ë‹¤ì–‘í•œ í•„í„°ë§ì„ ì ìš©í•´ë³´ì•˜ì§€ë§Œ, ì € ê²°ê³¼ê°€ ìµœì„ ì´ì—ˆë‹¤.

ê·¸ë˜ì„œ img2ë„ ë§ˆì°¬ê°€ì§€ë¡œ ì§ì ‘ ì„¤ì •í•œ ì»¤ë„ ì´í›„ ê°€ìš°ì‹œì•ˆ í•„í„°ë§, Clahe, Otsuâ€™s ì´ì§„í™”ë¥¼ ê±°ì³ ë‹¤ìŒì˜ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤.

![7](https://github.com/user-attachments/assets/bcace7d0-e733-4b6c-9aed-b2067db6e81b)

![8](https://github.com/user-attachments/assets/68a8d124-c656-4daf-b355-cc1b61792c83)

ì°¸ê³ ë¡œ ì´ì§„í™”ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥í•´ë³´ì•˜ë‹¤.

```python
fig, axes = plt.subplots(1,2,figsize = (18,5))
axes[0].hist(img1.ravel(), bins=256, color ="r");
axes[1].hist(img2.ravel(), bins=256);
```

ê²°ê³¼ëŠ” ì´ë¯¸ì§€ë“¤ì´ ì´ë¯¸ ìƒë‹¹íˆ ì´ì§„í™”ë˜ì–´ ìˆìŒì„ ë³´ì˜€ë‹¤.

![9](https://github.com/user-attachments/assets/db3efa2a-4179-4358-8f81-fce365428cb4)

## íŠ¹ì§• ì¶”ì¶œ

íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•´ `MinutiaeFeature`Â í´ë˜ìŠ¤, `features_to_array`Â í•¨ìˆ˜, `getTerminationBifurcation`Â í•¨ìˆ˜, `computeAngle`Â í•¨ìˆ˜, `extractMinutiaeFeatures`Â í•¨ìˆ˜, `ShowResults`Â í•¨ìˆ˜ë¥¼ ì‘ì„±í–ˆë‹¤.

`MinutiaeFeature`Â í´ë˜ìŠ¤ëŠ” ë¯¸ì„¸ íŠ¹ì§•ì„ ì €ì¥í•˜ê³  ë°°ì—´ë¡œ ë³€í™˜í•˜ë©°,Â `features_to_array`Â í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ íŠ¹ì§•ì„ ë°°ì—´ë¡œ ë³€í™˜í•˜ê³  íŒ¨ë”©í•œë‹¤.Â `getTerminationBifurcation`Â í•¨ìˆ˜ëŠ” ì§€ë¬¸ ì´ë¯¸ì§€ì—ì„œ ì¢…ë£Œì ê³¼ ë¶„ê¸°ì ì„ ì¶”ì¶œí•˜ê³ ,Â `computeAngle`Â í•¨ìˆ˜ëŠ” ë¸”ë¡ì—ì„œ ë¯¸ì„¸ íŠ¹ì§•ì˜ ê°ë„ë¥¼ ê³„ì‚°í•œë‹¤.Â `extractMinutiaeFeatures`Â í•¨ìˆ˜ëŠ” ê³¨ê²©í™”ëœ ì´ë¯¸ì§€ì™€ ì¶”ì¶œëœ ì¢…ë£Œì  ë° ë¶„ê¸°ì ì—ì„œ ë¯¸ì„¸ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ë©°,Â `ShowResults`Â í•¨ìˆ˜ëŠ” ì¶”ì¶œëœ ì¢…ë£Œì ê³¼ ë¶„ê¸°ì ì„ ì‹œê°í™”í•œë‹¤.

ì´ í•¨ìˆ˜ë“¤ì„ ì´ìš©í•´ img1, img2ì— ì ìš©í•´ ìŠ¤ì¼ˆë ˆí†¤í™”ì™€ íŠ¹ì§• ì¶”ì¶œì„ ì§„í–‰í•œ ê²°ê³¼, ê°ê° ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì™”ë‹¤.

![10](https://github.com/user-attachments/assets/13ad503a-d898-4c3f-ba03-32ddaaa545c1)

![11](https://github.com/user-attachments/assets/90007ba6-7be2-4875-92e7-f0920253d0b5)

ê·¸ í›„ íŠ¹ì§•ì ì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ë³‘í•©í•œ í›„ feat_query, feat_trainì™€ ê°ê°ì˜ ê°¯ìˆ˜ë¥¼ ì¶œë ¥í•´ë³´ì•˜ë‹¤. ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì•˜ë‹¤.

```python
feat_query: [[  10.   52. -135.    0.    0.]
 [  10.   71. -180.    0.    0.]
 [  10.   81. -135.    0.    0.]
 ...
 [ 239.  122.   90. -180.  -45.]
 [ 239.   65.  135.   45. -135.]
 [ 240.   90.   90. -180.   -0.]]
feat_train: [[  10.   72. -180.    0.    0.]
 [  10.  102. -180.    0.    0.]
 [  10.  120. -180.    0.    0.]
 ...
 [ 239.  122.   90. -180.  -45.]
 [ 239.   65.  135.   45. -135.]
 [ 240.   90.   90. -180.   -0.]]
398 356
```

## ë§¤ì¹­

ë¨¼ì € ë§¤ì¹­í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì§°ë‹¤.

```python
def match_finger(feat_query, feat_train, threshold, use_orientation, img_query=None, img_train=None):
    matches = []
    for i, q_feat in enumerate(feat_query):
        q_loc = q_feat[:2]
        q_orientation = q_feat[2:]
        for j, t_feat in enumerate(feat_train):
            t_loc = t_feat[:2]
            t_orientation = t_feat[2:]

            # Compute Euclidean distance between query and train locations
            loc_dist = distance.euclidean(q_loc, t_loc)

            if use_orientation:
                # Compute orientation distance if required
                if np.isnan(q_orientation).any() or np.isnan(t_orientation).any():
                    ori_dist = float('inf')
                else:
                    ori_dist = distance.euclidean(q_orientation, t_orientation)
                total_dist = loc_dist + ori_dist
            else:
                total_dist = loc_dist

            if total_dist < threshold:
                matches.append((i, j, total_dist))

    # Filter matches to find the best ones
    matches = sorted(matches, key=lambda x: x[2])
    unique_matches_query = set()
    unique_matches_train = set()
    best_matches = []
    for match in matches:
        if match[0] not in unique_matches_query and match[1] not in unique_matches_train:
            best_matches.append(match)
            unique_matches_query.add(match[0])
            unique_matches_train.add(match[1])

    dist = sum([match[2] for match in best_matches])
    dist_half = dist / 2
    len_match = len(best_matches)

    # Optionally, visualize the matches if images are provided
    if img_query is not None and img_train is not None:
        combined_img = np.concatenate((img_query, img_train), axis=1)
        plt.figure(figsize=(10, 5))
        plt.imshow(combined_img, cmap='gray')
        cols = img_query.shape[1]
        
        for match in best_matches:
            q_loc = feat_query[match[0]][:2]
            t_loc = feat_train[match[1]][:2]
            t_loc[1] += cols  # Adjust t_loc for the combined image
            
            color = get_random_color()
            plt.plot([q_loc[1], t_loc[1]], [q_loc[0], t_loc[0]], '-', color=color)
            plt.plot(q_loc[1], q_loc[0], 'o', color=color)
            plt.plot(t_loc[1], t_loc[0], 'o', color=color)
        plt.show()

    return dist, dist_half, len_match

def get_random_color():
    return [random.random(), random.random(), random.random()]
```

ì´ í•¨ìˆ˜ë¥¼ ì´ìš©í•´ dist, dist_half, len_matchë¥¼ ì¶œë ¥í•´ë³´ë‹ˆ img1, img2ì˜ ë§¤ì¹­ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì•˜ë‹¤.

```python
dist, dist_half, len_match = match_finger(feat_query, feat_train, 50, True, img_query=img1, img_train=img2)
print(dist, dist_half, len_match)
```

![12](https://github.com/user-attachments/assets/5534a6e7-ae2e-4ec7-8f96-82514f941203)

distëŠ” ëŒ€ëµ 492.901, len_matchëŠ” 336ì´ì—ˆë‹¤.

distê°€ ì–´ëŠ ì •ë„ ë˜ëŠ” ê²Œ ë§¤ì¹­ë˜ëŠ” ê²Œ ë§ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë‘ ë²ˆì§¸ í›ˆë ¨ ì´ë¯¸ì§€ë„ ë¡œë“œí•˜ì—¬ img2ì™€ ë¹„êµí•´ë³´ë‹ˆ ë‹¤ìŒì˜ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤.

![13](https://github.com/user-attachments/assets/6e716f5c-ce7d-4fc3-98ca-dcdc98278581)

![14](https://github.com/user-attachments/assets/c14553b3-ea90-4e5b-a13d-36d3075bac40)

 distëŠ” ëŒ€ëµ 5375.110, len_matchëŠ” 221ì´ì—ˆë‹¤.

ì´ ë‘ ê²°ê³¼ë¥¼ í†µí•´, ì„œë¡œ ë™ì¼í•œ ì§€ë¬¸ì˜ ê²½ìš° distê°€ ëŒ€ëµ 500~550 ì´í•˜ì´ê³ , ë‹¤ë¥¸ ì§€ë¬¸ì˜ ê²½ìš° distê°€ 4000~5000 ì´ìƒì´ë¼ê³  íŒë‹¨í•˜ì˜€ë‹¤. ê·¸ë˜ì„œ distê°€ 550 ì´í•˜ë©´ ì„œë¡œ ì¼ì¹˜í•˜ëŠ” ì§€ë¬¸ì´ë¼ íŒë‹¨í•˜ê³  ê²°ê³¼ì— ì €ì¥í•˜ë„ë¡ ì½”ë“œë¥¼ ì§°ë‹¤.

ìœ„ì™€ ê°™ì´ ì´ë¯¸ì§€ ì„¸ ê°œì— ëŒ€í•´ ë¶„ì„ì„ í•œ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ì²´ í›ˆë ¨ ì´ë¯¸ì§€ì™€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•´ ë§¤ì¹­ì„ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œë¥¼ ì§œ ì‹¤í–‰í•´ë³´ì•˜ë‹¤. ë§¤ì¹­ëœ ë‘ ì´ë¯¸ì§€ì™€ distanceë¥¼ ì¶œë ¥í•˜ë„ë¡ í–ˆë‹¤.

![15](https://github.com/user-attachments/assets/11949472-e69f-46aa-8d01-a5a9a79280c4)

ë§ˆì§€ë§‰ ì¶œë ¥ì€ ì´ëŸ° ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒˆë‹¤.

![16](https://github.com/user-attachments/assets/bc4b6bc7-1586-44bf-8f4a-5d028207b50c)

## Metric ê³„ì‚°

Precision, Recall, FAR, FRR, ACCë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì§°ë‹¤.

```python
def calculate_metrics(dict_result, threshold):
    TP = FP = FN = TN = 0
    for (test_img, train_img), (dist, dist_half, len_match, len_feat_query, len_feat_train) in dict_result.items():
        if dist < threshold:
            if os.path.basename(test_img).split('_')[0] == os.path.basename(train_img).split('_')[0]:
                TP += 1
            else:
                FP += 1
        else:
            if os.path.basename(test_img).split('_')[0] == os.path.basename(train_img).split('_')[0]:
                FN += 1
            else:
                TN += 1

    Precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    Recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    FAR = FP / (FP + TN) if (FP + TN) > 0 else 0
    FRR = FN / (TP + FN) if (TP + FN) > 0 else 0
    ACC = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0

    return Precision, Recall, FAR, FRR, ACC
```

ì´ì œ ì„ê³„ê°’ì„ 500ìœ¼ë¡œ ì„¤ì •í•œ í›„ ê³„ì‚°í–ˆë”ë‹ˆ ë‹¤ìŒì˜ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤.

```python
Precision: 0.0, Recall: 0, FAR: 0.9217758985200846, FRR: 0, ACC: 0.07822410147991543
```
